{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as math\n",
    "from numpy.typing import NDArray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nueron_layer2:\n",
    "    def __init__(self):\n",
    "        self.act_out = 0\n",
    "        self.lin_out = 0\n",
    "        self.weights = np.random.rand(9)\n",
    "    \n",
    "    def activation(self): # Implement Hard Sigmoid\n",
    "        #return np.clip((self.lin_out + 1) / 2, 0, 1\n",
    "        print(self.lin_out + 1)\n",
    "        return 0.8/(1 + math.exp(-self.lin_out))\n",
    "    \n",
    "    def forward_pass(self, input: np.array):#size 8 \n",
    "        self.lin_out = np.dot(input, self.weights)\n",
    "        self.act_out = self.activation()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nueron_layer1:\n",
    "    def __init__(self):\n",
    "        self.act_out = 0\n",
    "        self.lin_out = 0\n",
    "        self.weights = np.random.rand(10)\n",
    "    \n",
    "    def activation(self): # Implement ReLu\n",
    "        return np.clip(self.lin_out, 0, None)\n",
    "    \n",
    "    def forward_pass(self, input: np.array):#size 1\n",
    "        self.lin_out = np.dot(input, self.weights)\n",
    "        self.act_out = self.activation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def der_hard_sigmoid(x):\n",
    "    # if x > 1 or x < -1:\n",
    "    #     return 0\n",
    "    # elif x > -1 and x < 1:\n",
    "    #     return 1/2\n",
    "\n",
    "    return x*(1-x)\n",
    "\n",
    "def der_ReLu(x):\n",
    "\n",
    "    if x > 0 :\n",
    "        return 1\n",
    "    elif x < 0:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "class nn:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n2a = nueron_layer2()\n",
    "        self.n1 = [nueron_layer1() for i in range(8)]\n",
    "\n",
    "    def initalise_trainingdata(self, input:NDArray, labels, lr, niter):\n",
    "        self.n = len(input)\n",
    "        self.input = input\n",
    "        self.labels = labels\n",
    "        self.learning_rate = lr\n",
    "        self.niter = niter # number of iterations in one epoch\n",
    "\n",
    "    # input length 8\n",
    "    def ForwardPassNueralNet(self, index=0):       \n",
    "        \n",
    "        \n",
    "        for i in range(8):      \n",
    "            self.n1[i].forward_pass(np.array(self.input[index]))\n",
    "        n2a_input = [j.act_out for j in self.n1]        \n",
    "        n2a_input.append(1)\n",
    "        \n",
    "        self.n2a.forward_pass(input=n2a_input)\n",
    "\n",
    "\n",
    "    def gradient_calc(self): # one epoch\n",
    "    \n",
    "    # Square Loss ~ (output[i] - label[i])**2 ~ Is The Loss Function \n",
    "\n",
    "        \n",
    "        gradient_vector = np.zeros(8*10+9) # first 9 are parameters related to the only nueron in nueron layer 2\n",
    "                                    \n",
    "        \n",
    "        for i in range(len(self.input)):\n",
    "            self.ForwardPassNueralNet(i)\n",
    "           \n",
    "            for param in range(8):\n",
    "                gradient_vector[param] += 2*(self.n2a.act_out - self.labels[i])*der_hard_sigmoid(self.n2a.lin_out)*self.n1[param].act_out   \n",
    "            gradient_vector[8] += 2*(self.n2a.act_out - self.labels[i])*der_hard_sigmoid(self.n2a.lin_out)*1 # for the bias term\n",
    "            \n",
    "            for row in range(8):\n",
    "                for col in range(10):\n",
    "                    gradient_vector[9+row*10+col] += 2*(self.n2a.act_out - self.labels[i])*der_hard_sigmoid(self.n2a.lin_out)*self.n2a.weights[row]*der_ReLu(self.n1[row].lin_out)*self.input[i][col]\n",
    "        return gradient_vector\n",
    "        \n",
    "    \n",
    "\n",
    "    def gradient_descent(self):\n",
    "\n",
    "\n",
    "        for _ in range(self.niter):\n",
    "            gradients = self.gradient_calc()\n",
    "            \n",
    "            vec1 = self.n2a.weights\n",
    "            vec2 = np.array([self.n1[i].weights for i in range(len(self.n1))])\n",
    "            \n",
    "            weight_vec = np.concatenate((vec1, vec2.reshape(-1)))           \n",
    "            \n",
    "            new_weight_vec = weight_vec - self.learning_rate*gradients\n",
    "            assert(len(new_weight_vec) == 89)\n",
    "            count = np.zeros(89)\n",
    "            #assign the updates weights now:\n",
    "            self.n2a.weights = np.array(new_weight_vec[0:9])\n",
    "            for row in range(8):\n",
    "                for col in range(10):\n",
    "                    self.n1[row].weights[col] = weight_vec[9 + 10*row + col]\n",
    "                    count[9 + 10*row + col] += 1\n",
    "            \n",
    "\n",
    "    def calc_loss(self):\n",
    "        output = []\n",
    "        # first 8 are parameters related to the only nueron in nueron layer 2\n",
    "        # last 8 are parameters related to the 8 nueron in nueron layer 1\n",
    "        \n",
    "        for i in range(len(self.input)):\n",
    "            self.ForwardPassNueralNet(i)\n",
    "            output.append(self.n2a.act_out)\n",
    "\n",
    "        return sum([(self.labels[i] - output[i])**2 for i in range(len(output))])\n",
    "\n",
    "\n",
    "my_nn = nn()\n",
    "input_nn = [[2 ,2 ,4, 5, 5, 4, 1, 7, 0, 1],[2, 2, 3, 5, 4, 4, 0, 8, 0, 1]]\n",
    "labels = [1, 1 ]\n",
    "lr = 0.003\n",
    "niter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.10010965069986\n",
      "55.460876991413876\n",
      "59.10010965069986\n",
      "55.460876991413876\n",
      "-11932.44991263054\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "math range error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [203], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m my_nn\u001b[38;5;241m.\u001b[39mgradient_calc()\n\u001b[0;32m      3\u001b[0m my_nn\u001b[38;5;241m.\u001b[39mgradient_descent()\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmy_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn [202], line 76\u001b[0m, in \u001b[0;36mnn.calc_loss\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# first 8 are parameters related to the only nueron in nueron layer 2\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# last 8 are parameters related to the 8 nueron in nueron layer 1\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput)):\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mForwardPassNueralNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn2a\u001b[38;5;241m.\u001b[39mact_out)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m([(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[i] \u001b[38;5;241m-\u001b[39m output[i])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output))])\n",
      "Cell \u001b[1;32mIn [202], line 23\u001b[0m, in \u001b[0;36mnn.ForwardPassNueralNet\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     20\u001b[0m n2a_input \u001b[38;5;241m=\u001b[39m [j\u001b[38;5;241m.\u001b[39mact_out \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn1]        \n\u001b[0;32m     21\u001b[0m n2a_input\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn2a\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn2a_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [199], line 14\u001b[0m, in \u001b[0;36mnueron_layer2.forward_pass\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_pass\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: np\u001b[38;5;241m.\u001b[39marray):\u001b[38;5;66;03m#size 8 \u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [199], line 10\u001b[0m, in \u001b[0;36mnueron_layer2.activation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mactivation\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;66;03m# Implement Hard Sigmoid\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#return np.clip((self.lin_out + 1) / 2, 0, 1\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_out \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.8\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin_out\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mOverflowError\u001b[0m: math range error"
     ]
    }
   ],
   "source": [
    "my_nn.initalise_trainingdata(input_nn, labels, lr, niter)\n",
    "my_nn.gradient_calc()\n",
    "my_nn.gradient_descent()\n",
    "print(my_nn.calc_loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.6873422"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot([0.69381075, 0.77043915 ,0.15036522 ,0.33325319, 0.39468583, 0.34754608,\n",
    " 0.71602594, 0.99910301, 0.13833847, 0.41147616], [2 ,2 ,4, 5, 5, 4, 1, 0, 0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
